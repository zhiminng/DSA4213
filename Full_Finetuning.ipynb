{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oqU2BSuHF-1"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfey6jv6HpHH"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK3WHTVxH5lx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "f32f1d55b29a44dd93b6d35ec51285f6",
      "280b0536a7424137ad0d7f4722362370",
      "67676946513045fb8fafe56ab2dcb3c5",
      "72fbcfd640f2431b95df255bfb9d9428",
      "8413428a82c2471f81e174cadbedc35e",
      "287d25b6fd3044a28b05ff5620b3f6be",
      "13f7500f4ebc454891037eb2ed1bdd27",
      "615213f4f4724639a90ff043dc01dbdb",
      "e31143be8f65492099e11ef5ad5464a0",
      "32c6ac0bb29043408557559b92f4f0c0",
      "b2807b6767dd410a99b89ea3e60abb41",
      "c273d7c6461a4cf3a4cd1dd858c4da95",
      "6c17d39471df45e0ba3b1bf025ae3177",
      "a7a5e1c0b4b34aa59471c9d16f48c86c",
      "472ef4b1c4d041d99fc8e4f92668c16b",
      "09096e0c8ce84f21a0bbe5ebee422f94",
      "fa14ffd69d144a068fd872cb7c6f6d97",
      "cbddc409eaa846278419fef92d1704cf",
      "4e6be5f6b9e2470284cf9fa4936df991",
      "aaad6cbec5674db8b543e21119ba7cdd",
      "1f1f20126a3a4b61bf53280c1de4ea6b",
      "6b3118fa88274c879ade0ce07e61b6f2"
     ]
    },
    "id": "hs7ZMSrcH7Mq",
    "outputId": "9a8a0ea7-6411-483b-bb69-d40e365f16e6"
   },
   "outputs": [],
   "source": [
    "file_path = r\"/content/Sentences_66Agree.txt\"\n",
    "\n",
    "# Use cp1252 encoding instead of utf-8\n",
    "with open(file_path, 'r', encoding='cp1252') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Inspect\n",
    "print(lines[:5])\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    if \"@positive\" in line:\n",
    "        label = \"positive\"\n",
    "        text = line.replace(\"@positive\", \"\").strip()\n",
    "    elif \"@negative\" in line:\n",
    "        label = \"negative\"\n",
    "        text = line.replace(\"@negative\", \"\").strip()\n",
    "    elif \"@neutral\" in line:\n",
    "        label = \"neutral\"\n",
    "        text = line.replace(\"@neutral\", \"\").strip()\n",
    "    else:\n",
    "        continue  # skip malformed lines\n",
    "\n",
    "    sentences.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sentences.\")\n",
    "\n",
    "# 3Ô∏è‚É£ Map labels to integers\n",
    "df = pd.DataFrame({\"text\": sentences, \"label\": labels})\n",
    "df['label'] = df['label'].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2})\n",
    "\n",
    "# Inspect\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSBeYK0BH-c6",
    "outputId": "8028a4a4-2e25-4c77-eced-860caa1e48bf"
   },
   "outputs": [],
   "source": [
    "# Load FinBERT pre-trained for sentiment classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"yiyanghkust/finbert-tone\",\n",
    "    num_labels=3,  # positive, neutral, negative\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Model loaded with {model.num_parameters():,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIliUQepIAMS"
   },
   "outputs": [],
   "source": [
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"f1_negative\": f1_per_class[0],\n",
    "        \"f1_neutral\": f1_per_class[1],\n",
    "        \"f1_positive\": f1_per_class[2],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oionUXitIAyL"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finbert_full_ft\",\n",
    "    num_train_epochs=2,                 # Reduce epochs from 3 ‚Üí 2\n",
    "    per_device_train_batch_size=32,     # Increase batch size from 16 ‚Üí 32\n",
    "    per_device_eval_batch_size=32,      # Match eval batch size\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",        # Evaluate every few steps instead of full epoch\n",
    "    eval_steps=100,                     # Evaluate every 100 steps\n",
    "    save_strategy=\"steps\",              # Save checkpoints every few steps\n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    fp16=True,                          # Use mixed precision if GPU supports it\n",
    "    gradient_accumulation_steps=1,      # Can increase if GPU memory is limited\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pB8IULRqIIVz",
    "outputId": "20d39539-af82-49fa-ab9a-73d54da5632c"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "geJUpFMnyCnH",
    "outputId": "7d3f7e0b-8922-4306-f966-c89e34e3287a"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Starting full fine-tuning...\")\n",
    "eval_results_full = trainer.evaluate()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "for key, value in eval_results_full.items():\n",
    "    if key.startswith('eval_'):\n",
    "        metric_name = key.replace('eval_', '').upper()\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "predictions_full = trainer.predict(test_dataset)\n",
    "y_pred_full = np.argmax(predictions_full.predictions, axis=-1)\n",
    "y_true = predictions_full.label_ids\n",
    "\n",
    "# Save model\n",
    "print(\"\\nüíæ Saving full fine-tuned model...\")\n",
    "trainer.save_model(\"./news_classifier_full_finetuning\")\n",
    "tokenizer.save_pretrained(\"./news_classifier_full_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "SlPZzpKd0tNv",
    "outputId": "58702e6f-56e9-434a-9df6-fc78d2be7117"
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_full, target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_full)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"negative\", \"neutral\", \"positive\"], yticklabels=[\"negative\", \"neutral\", \"positive\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Full Fine-tuning\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrpckWQc2FKC",
    "outputId": "a21e5e7e-97a9-47aa-8f61-4b4a1cbb86f3"
   },
   "outputs": [],
   "source": [
    "metrics_df.head()\n",
    "metrics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "I2KGuqJB0_cB",
    "outputId": "a675c8ac-9dfc-4d87-b5b7-953db73078d4"
   },
   "outputs": [],
   "source": [
    "# Separate training and evaluation logs\n",
    "train_loss_df = metrics_df[metrics_df[\"loss\"].notnull()]\n",
    "eval_loss_df = metrics_df[metrics_df[\"eval_loss\"].notnull()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss_df[\"epoch\"], train_loss_df[\"loss\"], 'o-', label=\"Training Loss\")\n",
    "plt.plot(eval_loss_df[\"epoch\"], eval_loss_df[\"eval_loss\"], 's-', label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
