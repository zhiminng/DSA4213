{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oqU2BSuHF-1"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfey6jv6HpHH"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bK3WHTVxH5lx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495,
     "referenced_widgets": [
      "56daf3bb82294c09a8af09b190710a76",
      "ba654976bf6841bebdd2e5c1497e7a91",
      "03249543bd904694a9e11cc25fe4ebd9",
      "13e785c469ff4f8a8447e39e49fa6330",
      "7d7cc654f1cd4b54ac2d5920a3d961d8",
      "d1361216bab348e490b9ea4bd3c35442",
      "140aee9bd0274286b582093096106a05",
      "a7b95251893641d8a11ffb05ccd6e6d9",
      "2195811338d1418fb85d48122655be14",
      "61c4fac561934f79932e32acfc209f9c",
      "232d5bc973a54f048a83f28ebbd733b7",
      "480d5de3aceb48f697e493bcdd980a1c",
      "befcf93f7bd74dcb81174a6777c980cf",
      "4d4431c9add24661847aee9e660cccad",
      "d7fbfc2b739840769ed4216c9748c892",
      "ffef5b3a353a40b48ca4b44a6e7d553e",
      "d9766a2c587e4a3bbe2528fbead45ec6",
      "6635e000365e4e889459794b4aaec598",
      "7b78b774ce314fe781f13be3b1e8ca1f",
      "bce184bf62324a5989068ddd6c997e07",
      "39d22cc2e46b450dbd30fadf7c1e1519",
      "0ee04a98f1d242648f995c791467cb3c",
      "72565c597651461788777015d58e6651",
      "4bef70bb98a3489c8866b2481213986b",
      "c4b0184730b2475086bcf2168dd6dbda",
      "4d14aba635a14260b0b813174d21dd0a",
      "4a8f1e274a7041f9a4bb5e442c6837d7",
      "6e79d6fba11a40f4b84ddfb01d146cba",
      "09e760cefe7949f99a19eb4577ad34d7",
      "0c6f049fb26d4354b6f4f42a0fde2357",
      "9300ac236a8648fbbbbe05e4d818dd75",
      "efe9665546094450a71ec3de67279060",
      "646c78e66a0b463e998c3f3d56147699",
      "ebeb33f6d25e4f61871bf858db231054",
      "d320e47b4b42483a93eba5f8539b9b2a",
      "3174f5cb64f949d687404b5168d70756",
      "c229010eb2ee47d9bb4f4755aac740d5",
      "c34dee0356304b8b8bd4d48245d4252b",
      "c19439809e4e40659880dcf24516bc86",
      "fd60ee06377b4da2b1083f9c8ba09d6f",
      "0b4cfb46c4544a0589cf62608d608c21",
      "a5b81b238c7c43cabd9e8506e87c7733",
      "7159efc18f92417f97ce821fe5cd535d",
      "ffeae1bdcc2c45dd99ee9b63d133576c"
     ]
    },
    "id": "hs7ZMSrcH7Mq",
    "outputId": "dc40d200-6560-4898-909d-a97cf05430c7"
   },
   "outputs": [],
   "source": [
    "file_path = r\"/content/Sentences_66Agree.txt\"\n",
    "\n",
    "# Use cp1252 encoding instead of utf-8\n",
    "with open(file_path, 'r', encoding='cp1252') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Inspect\n",
    "print(lines[:5])\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    if \"@positive\" in line:\n",
    "        label = \"positive\"\n",
    "        text = line.replace(\"@positive\", \"\").strip()\n",
    "    elif \"@negative\" in line:\n",
    "        label = \"negative\"\n",
    "        text = line.replace(\"@negative\", \"\").strip()\n",
    "    elif \"@neutral\" in line:\n",
    "        label = \"neutral\"\n",
    "        text = line.replace(\"@neutral\", \"\").strip()\n",
    "    else:\n",
    "        continue  # skip malformed lines\n",
    "\n",
    "    sentences.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sentences.\")\n",
    "\n",
    "# 3️⃣ Map labels to integers\n",
    "df = pd.DataFrame({\"text\": sentences, \"label\": labels})\n",
    "df['label'] = df['label'].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2})\n",
    "\n",
    "# Inspect\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "dbd2616a40e8429f97c9bb18f24dded7",
      "156c0ee22da046c8843e7ef81b5eba37",
      "026b9fc637f84616bba4f4b78f88a204",
      "69a6395958a745adaf921c7b46f0c7bb",
      "b2c1ab0a1ca04a0486a84504fb8cc709",
      "9e73792f14324196b41fb551f437e1f4",
      "7eff51502e034cecaa497012ef2c68a4",
      "803a7157b4034a419420d294722d07f6",
      "4f87b6641a954c49baec71e8d626cbbb",
      "a1be98fe26204c46afdf6e07663ca856",
      "3aa746707c7f47edaae117ce407a9991",
      "ca0072a938504119a4c6146657b8845e",
      "95e43c1b4c194f56af5ca8b101f709b8",
      "5eb7cb9124eb44f684bdcd8eb522ae1e",
      "5dd50160dd4f4447a39dbd7f67092a68",
      "1c9a4df5785a40c0a41fe989aa722981",
      "89eb24f10d0145efb39467c9ec69d28c",
      "e19f832c353c448487cb1ec64b5cf61a",
      "1f6d1d97b27d44128fe410caa0b9b283",
      "3a7a00d2baa04ae39d62de001279e24d",
      "944744755f474dba9814c7d2a1ae45a2",
      "5f604310a3e148b78afc399e8418ce87"
     ]
    },
    "id": "PSBeYK0BH-c6",
    "outputId": "c01b5e7f-fe30-4ede-e417-16c9c3e0d9c5"
   },
   "outputs": [],
   "source": [
    "# Load FinBERT pre-trained for sentiment classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"yiyanghkust/finbert-tone\",\n",
    "    num_labels=3,  # positive, neutral, negative\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Model loaded with {model.num_parameters():,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIliUQepIAMS"
   },
   "outputs": [],
   "source": [
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    f1_per_class = f1_score(labels, predictions, average=None)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"f1_negative\": f1_per_class[0],\n",
    "        \"f1_neutral\": f1_per_class[1],\n",
    "        \"f1_positive\": f1_per_class[2],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oionUXitIAyL"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finbert_full_ft\",\n",
    "    num_train_epochs=2,                 # Reduce epochs from 3 → 2\n",
    "    per_device_train_batch_size=32,     # Increase batch size from 16 → 32\n",
    "    per_device_eval_batch_size=32,      # Match eval batch size\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",        # Evaluate every few steps instead of full epoch\n",
    "    eval_steps=100,                     # Evaluate every 100 steps\n",
    "    save_strategy=\"steps\",              # Save checkpoints every few steps\n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    fp16=True,                          # Use mixed precision if GPU supports it\n",
    "    gradient_accumulation_steps=1,      # Can increase if GPU memory is limited\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pB8IULRqIIVz",
    "outputId": "f6ab4154-053f-431b-96bf-6ad24be6909e"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "geJUpFMnyCnH",
    "outputId": "4ee7399e-33a1-431b-9da1-b8c2959b2107"
   },
   "outputs": [],
   "source": [
    "print(\"\\n🚀 Starting full fine-tuning...\")\n",
    "eval_results_full = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "for key, value in eval_results_full.items():\n",
    "    if key.startswith('eval_'):\n",
    "        metric_name = key.replace('eval_', '').upper()\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "predictions_full = trainer.predict(test_dataset)\n",
    "y_pred_full = np.argmax(predictions_full.predictions, axis=-1)\n",
    "y_true = predictions_full.label_ids\n",
    "\n",
    "# Save model\n",
    "print(\"\\n💾 Saving full fine-tuned model...\")\n",
    "trainer.save_model(\"./news_classifier_full_finetuning\")\n",
    "tokenizer.save_pretrained(\"./news_classifier_full_finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "SlPZzpKd0tNv",
    "outputId": "593c0512-abb9-4c23-f207-f79da717b7ed"
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_full, target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_full)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"negative\", \"neutral\", \"positive\"])\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"negative\", \"neutral\", \"positive\"], yticklabels=[\"negative\", \"neutral\", \"positive\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Full Fine-tuning\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrpckWQc2FKC",
    "outputId": "767d5c39-9947-4488-b4fa-4810aa996cc0"
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(trainer.state.log_history)\n",
    "metrics_df.head()\n",
    "metrics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "I2KGuqJB0_cB",
    "outputId": "8664ae70-ffa6-43c6-c24e-769e9b3f04f1"
   },
   "outputs": [],
   "source": [
    "# Separate training and evaluation logs\n",
    "train_loss_df = metrics_df[metrics_df[\"loss\"].notnull()]\n",
    "eval_loss_df = metrics_df[metrics_df[\"eval_loss\"].notnull()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss_df[\"epoch\"], train_loss_df[\"loss\"], 'o-', label=\"Training Loss\")\n",
    "plt.plot(eval_loss_df[\"epoch\"], eval_loss_df[\"eval_loss\"], 's-', label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
